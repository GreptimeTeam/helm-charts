image:
  # -- The image registry
  registry: docker.io
  # -- The image repository
  repository: greptime/greptimedb
  # -- The image tag
  tag: "v0.17.2"
  # -- The image pull secrets
  pullSecrets: []

# -- Custom image registry
customImageRegistry:
  # -- Whether to enable custom image registry and generate a pull secret in the release namespace
  enabled: false
  # -- The name of the pull secret. You can use the name in `image.pullSecrets`.
  secretName: greptimedb-custom-image-pull-secret
  # -- The registry of the custom image
  registry: ""
  # -- The username of the custom image
  username: ""
  # -- The password of the custom image
  password: ""

# -- additional labels to add to all resources
additionalLabels: {}

initializer:
  # -- Initializer image registry
  registry: docker.io
  # -- Initializer image repository
  repository: greptime/greptimedb-initializer
  # -- Initializer image tag
  tag: v0.5.2

base:
  # -- The pod template for base
  podTemplate:
    # -- The base spec of main container
    main:
      resources: {}
      # -- The requested resources for the container
      #  requests:
      #    cpu: 500m
      #    memory: 512Mi

      # -- The resources limits for the container
      #  limits:
      #    cpu: '1'
      #    memory: "1Gi"

      # -- The environment variables for the container
      env: []

      # -- The command to be executed in the container
      command: []

      # -- The arguments to be passed to the command
      args: []

      # -- The ExtraArgs specifies additional command-line arguments for the container entrypoint
      extraArgs: []

      # -- The config for startup probe of the main container
      startupProbe: {}
#        httpGet:
#          # -- Path to access on the HTTP server
#          path: /health
#          # -- Name or number of the port to access on the container
#          port: 4000
#          # -- The initial delay seconds for the readiness probe.
#          initialDelaySeconds: 5
#          # -- The timeout seconds for the readiness probe
#          timeoutSeconds: 1
#          # -- The period seconds for the readiness probe
#          periodSeconds: 10
#          # -- The success threshold for the readiness probe
#          successThreshold: 1
#          # -- The failure threshold for the readiness probe
#          failureThreshold: 3

      # -- The config for readiness probe of the main container
      readinessProbe: {}
#        httpGet:
#        # -- Path to access on the HTTP server
#          path: /health
#        # -- Name or number of the port to access on the container
#          port: 4000
#        # -- The initial delay seconds for the readiness probe
#        initialDelaySeconds: 5
#        # -- The timeout seconds for the readiness probe
#        timeoutSeconds: 1
#        # -- The period seconds for the readiness probe
#        periodSeconds: 10
#        # -- The success threshold for the readiness probe
#        successThreshold: 1
#        # -- The failure threshold for the readiness probe
#        failureThreshold: 3

      # -- The config for liveness probe of the main container
      livenessProbe: {}
#        httpGet:
#        # -- Path to access on the HTTP server
#          path: /health
#        # -- Name or number of the port to access on the container
#          port: 4000
#        # -- The initial delay seconds for the readiness probe.
#        initialDelaySeconds: 5
#        # -- The timeout seconds for the readiness probe
#        timeoutSeconds: 1
#        # -- The period seconds for the readiness probe
#        periodSeconds: 10
#        # -- The success threshold for the readiness probe
#        successThreshold: 1
#        # -- The failure threshold for the readiness probe
#        failureThreshold: 3

      # -- The configurations for security context of main container.
      securityContext: {}

    # -- The annotations to be created to the pod.
    annotations: {}
    # -- The labels to be created to the pod.
    labels: {}
    # -- The pod node selector
    nodeSelector: {}
    # -- The pod tolerations
    tolerations: []
    # -- The pod affinity
    affinity: {}
    # -- The global service account
    serviceAccountName: ""
    # -- The configurations for pod security context.
    securityContext: {}
    # -- The termination grace period seconds
    terminationGracePeriodSeconds: 30

# -- Frontend configure
frontend:
  enabled: true

  # -- Frontend replicas
  replicas: 1

  # -- Extra toml file of frontend.
  configFile: ""

  # -- Extra raw toml config data of frontend. Skip if the `configFile` is used.
  configData: ""

  # -- The pod template for frontend
  podTemplate:
    # -- The spec of main container
    main:
      # -- The frontend image.
      image: ""

      resources: {}
      # -- The requested resources for the container
      #  requests:
      #    cpu: '1'
      #    memory: "2Gi"

      # -- The resources limits for the container
      #  limits:
      #    cpu: '1'
      #    memory: "2Gi"

      # -- The environment variables for the container
      env: []

      # -- The command to be executed in the container
      command: []

      # -- The arguments to be passed to the command
      args: []

      # -- The ExtraArgs specifies additional command-line arguments for the container entrypoint
      extraArgs: []

      # -- The pod volumeMounts
      volumeMounts: []

      # -- The config for startup probe of the main container
      startupProbe: {}
#        httpGet:
#          # -- Path to access on the HTTP server
#          path: /health
#          # -- Name or number of the port to access on the container
#          port: 4000
#          # -- The initial delay seconds for the readiness probe.
#          initialDelaySeconds: 5
#          # -- The timeout seconds for the readiness probe
#          timeoutSeconds: 1
#          # -- The period seconds for the readiness probe
#          periodSeconds: 10
#          # -- The success threshold for the readiness probe
#          successThreshold: 1
#          # -- The failure threshold for the readiness probe
#          failureThreshold: 3

      # -- The config for readiness probe of the main container
      readinessProbe: {}
#        httpGet:
#        # -- Path to access on the HTTP server
#          path: /health
#        # -- Name or number of the port to access on the container
#          port: 4000
#        # -- The initial delay seconds for the readiness probe.
#        initialDelaySeconds: 5
#        # -- The timeout seconds for the readiness probe
#        timeoutSeconds: 1
#        # -- The period seconds for the readiness probe
#        periodSeconds: 10
#        # -- The success threshold for the readiness probe
#        successThreshold: 1
#        # -- The failure threshold for the readiness probe
#        failureThreshold: 3

      # -- The config for liveness probe of the main container
      livenessProbe: {}
#        httpGet:
#        # -- Path to access on the HTTP server
#          path: /health
#        # -- Name or number of the port to access on the container
#          port: 4000
#        # -- The initial delay seconds for the readiness probe.
#        initialDelaySeconds: 5
#        # -- The timeout seconds for the readiness probe
#        timeoutSeconds: 1
#        # -- The period seconds for the readiness probe
#        periodSeconds: 10
#        # -- The success threshold for the readiness probe
#        successThreshold: 1
#        # -- The failure threshold for the readiness probe
#        failureThreshold: 3

      # -- The configurations for frontend container.
      securityContext: {}

    # -- The annotations to be created to the pod.
    annotations: {}
    # -- The labels to be created to the pod.
    labels: {}
    # -- The pod node selector
    nodeSelector: {}
    # -- The pod tolerations
    tolerations: []
    # -- The pod affinity
    affinity: {}
    # -- The pod volumes
    volumes: []

    serviceAccount:
      # -- Create a service account
      create: false
      # -- The annotations for frontend serviceaccount
      annotations: {}

    # -- The configurations for frontend security context.
    securityContext: {}

    # -- The termination grace period seconds
    # terminationGracePeriodSeconds: 30

  # -- Frontend service
  service: {}

  # -- Frontend tls configure
  tls: {}
#    secretName: greptimedb-frontend-tls

  # -- Frontend internal port.
  # internalPort: 4010

  # -- Logging configuration for frontend, if not set, it will use the global logging configuration.
  logging: {}
#    # -- The log level for greptimedb, only support "debug", "info", "warn", "debug"
#    level: "info"
#
#    # -- The log format for greptimedb, only support "json" and "text"
#    format: "text"
#
#    # -- The logs directory for greptimedb
#    logsDir: "/data/greptimedb/logs"
#
#    # -- Whether to log to stdout only
#    onlyLogToStdout: false
#
#    # -- indicates whether to persist the log with the datanode data storage. It **ONLY** works for the datanode component.
#    persistentWithData: false
#
#    # -- The log filters, use the syntax of `target[span\{field=value\}]=level` to filter the logs.
#    filters: []

  # -- Tracing configuration for frontend, if not set, it will use the global logging configuration.
  tracing:
    # -- Enable tracing.
    enabled: false

    # -- The OTLP tracing endpoint.
    endpoint: "http://mycluster-monitor-standalone.default:4000/v1/otlp/v1/traces"

    # -- SampleRatio is the percentage of tracing will be sampled and exported.
    # Valid range `[0, 1]`, 1 means all traces are sampled, 0 means all traces are not sampled, the default value is 1.
    sampleRatio: "1.0"

  # -- Whether to enable object storage on frontend.
  enableObjectStorage: false

# -- Meta configure
meta:
  # -- Meta replicas
  replicas: 1

  # -- Extra toml file of meta.
  configFile: ""

  # -- Extra raw toml config data of meta. Skip if the `configFile` is used.
  configData: ""

  # -- The pod template for meta
  podTemplate:
    # -- The spec of main container
    main:
      # -- The meta image.
      image: ""

      resources: {}
      # -- The requested resources for the container
      #  requests:
      #    cpu: '1'
      #    memory: "2Gi"

      # -- The resources limits for the container
      #  limits:
      #    cpu: '1'
      #    memory: "2Gi"

      # -- The environment variables for the container
      env: []

      # -- The command to be executed in the container
      command: []

      # -- The arguments to be passed to the command
      args: []

      # -- The ExtraArgs specifies additional command-line arguments for the container entrypoint
      extraArgs: []

      # -- The pod volumeMounts
      volumeMounts: []

      # -- The config for startup probe of the main container
      startupProbe: {}
#        httpGet:
#          # -- Path to access on the HTTP server
#          path: /health
#          # -- Name or number of the port to access on the container
#          port: 4000
#          # -- The initial delay seconds for the readiness probe.
#          initialDelaySeconds: 5
#          # -- The timeout seconds for the readiness probe
#          timeoutSeconds: 1
#          # -- The period seconds for the readiness probe
#          periodSeconds: 10
#          # -- The success threshold for the readiness probe
#          successThreshold: 1
#          # -- The failure threshold for the readiness probe
#          failureThreshold: 3

      # -- The config for readiness probe of the main container
      readinessProbe: {}
#        httpGet:
#        # -- Path to access on the HTTP server
#          path: /health
#        # -- Name or number of the port to access on the container
#          port: 4000
#        # -- The initial delay seconds for the readiness probe.
#        initialDelaySeconds: 5
#        # -- The timeout seconds for the readiness probe
#        timeoutSeconds: 1
#        # -- The period seconds for the readiness probe
#        periodSeconds: 10
#        # -- The success threshold for the readiness probe
#        successThreshold: 1
#        # -- The failure threshold for the readiness probe
#        failureThreshold: 3

      # -- The config for liveness probe of the main container
      livenessProbe: {}
#        httpGet:
#        # -- Path to access on the HTTP server
#          path: /health
#        # -- Name or number of the port to access on the container
#          port: 4000
#        # -- The initial delay seconds for the readiness probe.
#        initialDelaySeconds: 5
#        # -- The timeout seconds for the readiness probe
#        timeoutSeconds: 1
#        # -- The period seconds for the readiness probe
#        periodSeconds: 10
#        # -- The success threshold for the readiness probe
#        successThreshold: 1
#        # -- The failure threshold for the readiness probe
#        failureThreshold: 3

      # -- The configurations for meta security context.
      securityContext: {}

    # -- The annotations to be created to the pod.
    annotations: {}
    # -- The labels to be created to the pod.
    labels: {}
    # -- The pod node selector
    nodeSelector: {}
    # -- The pod tolerations
    tolerations: []
    # -- The pod affinity
    affinity: {}
    # -- The pod volumes
    volumes: []

    serviceAccount:
      # -- Create a service account
      create: false
      # -- The annotations for meta serviceaccount
      annotations: {}

    # -- The configurations for meta security context.
    securityContext: {}

    # -- The termination grace period seconds
    # terminationGracePeriodSeconds: 30

  # -- Deprecated: Meta etcd endpoints, use `backendStorage.etcd.etcdEndpoints` instead
  etcdEndpoints: "etcd.etcd-cluster.svc.cluster.local:2379"

  # -- Deprecated: Meta will store data with this key prefix
  storeKeyPrefix: ""

  # -- Whether to enable region failover
  enableRegionFailover: false

  # -- Meta Backend storage configuration
  backendStorage:
    # -- MySQL backend storage configuration
    mysql: {}
      # # -- MySQL host
      # host: "mysql.default.svc.cluster.local"
      # # -- MySQL port
      # port: 3306
      # # -- MySQL database
      # database: "metasrv"
      # # -- MySQL table
      # table: "greptime_metakv"
      # # -- MySQL credentials
      # credentials:
      #   # -- MySQL credentials secret name
      #   secretName: "meta-mysql-credentials"
      #   # -- MySQL credentials existing secret name
      #   existingSecretName: ""
      #   # -- MySQL credentials username
      #   username: "root"
      #   # -- MySQL credentials password
      #   password: "test"

    # -- PostgreSQL backend storage configuration
    postgresql: {}
      # # -- PostgreSQL host
      # host: "postgres.default.svc.cluster.local"
      # # -- PostgreSQL port
      # port: 5432
      # # -- PostgreSQL database
      # database: "metasrv"
      # # -- PostgreSQL table
      # table: "greptime_metakv"
      # # -- PostgreSQL Advisory lock id used for election, shouldn't be used in other clusters or applications.
      # electionLockID: 1

      # # -- PostgreSQL credentials
      # credentials:
      #   # -- PostgreSQL credentials secret name
      #   secretName: "meta-postgresql-credentials"
      #   # -- PostgreSQL credentials existing secret name
      #   existingSecretName: ""
      #   # -- PostgreSQL credentials username
      #   username: "root"
      #   # -- PostgreSQL credentials password
      #   password: "root"

    # -- Etcd backend storage configuration
    etcd: {}
      # # -- Etcd endpoints
      # endpoints: "etcd.etcd-cluster.svc.cluster.local:2379"
      # # -- Etcd store key prefix
      # storeKeyPrefix: ""

  # -- Logging configuration for meta, if not set, it will use the global logging configuration.
  logging: {}
#    # -- The log level for greptimedb, only support "debug", "info", "warn", "debug"
#    level: "info"
#
#    # -- The log format for greptimedb, only support "json" and "text"
#    format: "text"
#
#    # -- The logs directory for greptimedb
#    logsDir: "/data/greptimedb/logs"
#
#    # -- Whether to log to stdout only
#    onlyLogToStdout: false
#
#    # -- indicates whether to persist the log with the datanode data storage. It **ONLY** works for the datanode component.
#    persistentWithData: false
#
#    # -- The log filters, use the syntax of `target[span\{field=value\}]=level` to filter the logs.
#    filters: []

  # -- Tracing configuration for meta, if not set, it will use the global logging configuration.
  tracing:
    # -- Enable tracing.
    enabled: false

    # -- The OTLP tracing endpoint.
    endpoint: "http://mycluster-monitor-standalone.default:4000/v1/otlp/v1/traces"

    # -- SampleRatio is the percentage of tracing will be sampled and exported.
    # Valid range `[0, 1]`, 1 means all traces are sampled, 0 means all traces are not sampled, the default value is 1.
    sampleRatio: "1.0"

# -- Datanode configure
datanode:
  enabled: true

  # -- Datanode replicas
  replicas: 1

  # -- Extra toml file of datanode.
  configFile: ""

  # -- Extra raw toml config data of datanode. Skip if the `configFile` is used.
  configData: ""

  # -- The pod template for datanode
  podTemplate:
    # -- The spec of main container
    main:
      # -- The datanode image.
      image: ""

      resources: {}
      # -- The requested resources for the container
      #  requests:
      #    cpu: '1'
      #    memory: "2Gi"

      # -- The resources limits for the container
      #  limits:
      #    cpu: '1'
      #    memory: "2Gi"

      # -- The environment variables for the container
      env: []

      # -- The command to be executed in the container
      command: []

      # -- The arguments to be passed to the command
      args: []

      # -- The ExtraArgs specifies additional command-line arguments for the container entrypoint
      extraArgs: []

      # -- The pod volumeMounts
      volumeMounts: []
      # -- The config for startup probe of the main container
      startupProbe: {}
#        httpGet:
#          # -- Path to access on the HTTP server
#          path: /health
#          # -- Name or number of the port to access on the container
#          port: 4000
#          # -- The initial delay seconds for the readiness probe.
#          initialDelaySeconds: 5
#          # -- The timeout seconds for the readiness probe
#          timeoutSeconds: 1
#          # -- The period seconds for the readiness probe
#          periodSeconds: 10
#          # -- The success threshold for the readiness probe
#          successThreshold: 1
#          # -- The failure threshold for the readiness probe
#          failureThreshold: 3

      # -- The config for readiness probe of the main container
      readinessProbe: {}
#        httpGet:
#        # -- Path to access on the HTTP server
#          path: /health
#        # -- Name or number of the port to access on the container
#          port: 4000
#        # -- The initial delay seconds for the readiness probe.
#        initialDelaySeconds: 5
#        # -- The timeout seconds for the readiness probe
#        timeoutSeconds: 1
#        # -- The period seconds for the readiness probe
#        periodSeconds: 10
#        # -- The success threshold for the readiness probe
#        successThreshold: 1
#        # -- The failure threshold for the readiness probe
#        failureThreshold: 3

      # -- The config for liveness probe of the main container
      livenessProbe: {}
#        httpGet:
#        # -- Path to access on the HTTP server
#          path: /health
#        # -- Name or number of the port to access on the container
#          port: 4000
#        # -- The initial delay seconds for the readiness probe.
#        initialDelaySeconds: 5
#        # -- The timeout seconds for the readiness probe
#        timeoutSeconds: 1
#        # -- The period seconds for the readiness probe
#        periodSeconds: 10
#        # -- The success threshold for the readiness probe
#        successThreshold: 1
#        # -- The failure threshold for the readiness probe
#        failureThreshold: 3

      # -- The configurations for datanode security context.
      securityContext: {}

    # -- The annotations to be created to the pod.
    annotations: {}
    # -- The labels to be created to the pod.
    labels: {}
    # -- The pod node selector
    nodeSelector: {}
    # -- The pod tolerations
    tolerations: []
    # -- The pod affinity
    affinity: {}
    # -- The pod volumes
    volumes: []

    serviceAccount:
      # -- Create a service account
      create: false
      # -- The annotations for datanode serviceaccount
      annotations: {}

    # -- The configurations for datanode security context.
    securityContext: {}

    # -- The termination grace period seconds
    # terminationGracePeriodSeconds: 30

  storage:
    # -- Storage class for datanode persistent volume
    storageClassName: null
    # -- Storage size for datanode persistent volume
    storageSize: 20Gi
    # -- Storage retain policy for datanode persistent volume
    storageRetainPolicy: Retain
    # -- The dataHome directory, default is "/data/greptimedb/"
    dataHome: "/data/greptimedb"
    # -- The data directory of the storage, default is "/data/greptimedb"
    mountPath: "/data/greptimedb"
    # -- The labels for the PVC that will be created
    labels: {}
    # -- The annotations for the PVC that will be created
    annotations: {}
    # -- The useEmptyDir is a flag to indicate whether to use an empty dir. If true, the PVC will not be created and the whole storage of datanode will be cleaned up when the datanode restarts.
    useEmptyDir: false

  # -- Logging configuration for datanode, if not set, it will use the global logging configuration.
  logging: {}
#    # -- The log level for greptimedb, only support "debug", "info", "warn", "debug"
#    level: "info"
#
#    # -- The log format for greptimedb, only support "json" and "text"
#    format: "text"
#
#    # -- The logs directory for greptimedb
#    logsDir: "/data/greptimedb/logs"
#
#    # -- Whether to log to stdout only
#    onlyLogToStdout: false
#
#    # -- indicates whether to persist the log with the datanode data storage. It **ONLY** works for the datanode component.
#    persistentWithData: false
#
#    # -- The log filters, use the syntax of `target[span\{field=value\}]=level` to filter the logs.
#    filters: []

  # -- Tracing configuration for datanode, if not set, it will use the global logging configuration.
  tracing:
    # -- Enable tracing.
    enabled: false

    # -- The OTLP tracing endpoint.
    endpoint: "http://mycluster-monitor-standalone.default:4000/v1/otlp/v1/traces"

    # -- SampleRatio is the percentage of tracing will be sampled and exported.
    # Valid range `[0, 1]`, 1 means all traces are sampled, 0 means all traces are not sampled, the default value is 1.
    sampleRatio: "1.0"

# -- Flownode configure.
flownode:
  # -- Enable flownode
  enabled: true

  # -- Flownode replicas
  replicas: 1

  # -- Extra toml file of flownode.
  configFile: ""

  # -- Extra raw toml config data of flownode. Skip if the `configFile` is used.
  configData: ""

  # -- Logging configuration for flownode, if not set, it will use the global logging configuration.
  logging: {}
#      # -- The log level for greptimedb, only support "debug", "info", "warn", "debug"
#      level: "info"
#
#      # -- The log format for greptimedb, only support "json" and "text"
#      format: "text"
#
#      # -- The logs directory for greptimedb
#      logsDir: "/data/greptimedb/logs"
#
#      # -- Whether to log to stdout only
#      onlyLogToStdout: false
#
#      # -- indicates whether to persist the log with the datanode data storage. It **ONLY** works for the datanode component.
#      persistentWithData: false
#
#      # -- The log filters, use the syntax of `target[span\{field=value\}]=level` to filter the logs.
#      filters: []

  # -- Tracing configuration for flownode, if not set, it will use the global logging configuration.
  tracing:
    # -- Enable tracing.
    enabled: false

    # -- The OTLP tracing endpoint.
    endpoint: "http://mycluster-monitor-standalone.default:4000/v1/otlp/v1/traces"

    # -- SampleRatio is the percentage of tracing will be sampled and exported.
    # Valid range `[0, 1]`, 1 means all traces are sampled, 0 means all traces are not sampled, the default value is 1.
    sampleRatio: "1.0"

  # -- The pod template for frontend
  podTemplate:
    # -- The spec of main container
    main:
      # -- The flownode image.
      image: ""

      resources: {}
      # -- The requested resources for the container
      #  requests:
      #    cpu: '1'
      #    memory: "2Gi"

      # -- The resources limits for the container
      #  limits:
      #    cpu: '1'
      #    memory: "2Gi"

      # -- The environment variables for the container
      env: []

      # -- The command to be executed in the container
      command: []

      # -- The arguments to be passed to the command
      args: []

      # -- The ExtraArgs specifies additional command-line arguments for the container entrypoint
      extraArgs: []

      # -- The pod volumeMounts
      volumeMounts: []

      # -- The config for startup probe of the main container
      startupProbe: {}
#        httpGet:
#          # -- Path to access on the HTTP server
#          path: /health
#          # -- Name or number of the port to access on the container
#          port: 4000
#          # -- The initial delay seconds for the readiness probe.
#          initialDelaySeconds: 5
#          # -- The timeout seconds for the readiness probe
#          timeoutSeconds: 1
#          # -- The period seconds for the readiness probe
#          periodSeconds: 10
#          # -- The success threshold for the readiness probe
#          successThreshold: 1
#          # -- The failure threshold for the readiness probe
#          failureThreshold: 3

      # -- The config for readiness probe of the main container
      readinessProbe: {}
#        httpGet:
#        # -- Path to access on the HTTP server
#          path: /health
#        # -- Name or number of the port to access on the container
#          port: 4000
#        # -- The initial delay seconds for the readiness probe.
#        initialDelaySeconds: 5
#        # -- The timeout seconds for the readiness probe
#        timeoutSeconds: 1
#        # -- The period seconds for the readiness probe
#        periodSeconds: 10
#        # -- The success threshold for the readiness probe
#        successThreshold: 1
#        # -- The failure threshold for the readiness probe
#        failureThreshold: 3

      # -- The config for liveness probe of the main container
      livenessProbe: {}
#        httpGet:
#        # -- Path to access on the HTTP server
#          path: /health
#        # -- Name or number of the port to access on the container
#          port: 4000
#        # -- The initial delay seconds for the readiness probe.
#        initialDelaySeconds: 5
#        # -- The timeout seconds for the readiness probe
#        timeoutSeconds: 1
#        # -- The period seconds for the readiness probe
#        periodSeconds: 10
#        # -- The success threshold for the readiness probe
#        successThreshold: 1
#        # -- The failure threshold for the readiness probe
#        failureThreshold: 3

      # -- The configurations for flownode security context.
      securityContext: {}

    # -- The annotations to be created to the pod.
    annotations: {}
    # -- The labels to be created to the pod.
    labels: {}
    # -- The pod node selector
    nodeSelector: {}
    # -- The pod tolerations
    tolerations: []
    # -- The pod affinity
    affinity: {}
    # -- The pod volumes
    volumes: []

    serviceAccount:
      # -- Create a service account
      create: false
      # -- The annotations for flownode serviceaccount
      annotations: {}

    # -- The configurations for flownode security context.
    securityContext: {}

    # -- The termination grace period seconds
    # terminationGracePeriodSeconds: 30

# -- Frontend instance groups configure
frontendGroups: []
#  # -- Custom frontend name
#  - name: read
#    replicas: 1
#
#    # -- Extra raw toml config data of frontend.
#    config: |
#      default_timezone = "UTC"
#
#      [http]
#      timeout = "10s"
#
#    # -- The pod template for frontend
#    template:
#      main:
#        resources:
#          requests:
#            cpu: 2000m
#            memory: 2048Mi
#          limits:
#            cpu: 2000m
#            memory: 2048Mi
#
#  # -- Custom frontend name
#  - name: write
#    replicas: 1
#
#    # -- Extra raw toml config data of frontend.
#    config: |
#      default_timezone = "UTC"
#
#      [http]
#      timeout = "10s"
#
#    # -- The pod template for frontend
#    template:
#      main:
#        resources:
#          requests:
#            cpu: 2000m
#            memory: 2048Mi
#          limits:
#            cpu: 2000m
#            memory: 2048Mi

# -- GreptimeDB http service port
httpServicePort: 4000
# -- GreptimeDB grpc service port
grpcServicePort: 4001
# -- GreptimeDB mysql service port
mysqlServicePort: 4002
# -- GreptimeDB postgres service port
postgresServicePort: 4003

# -- Configure to prometheus PodMonitor
prometheusMonitor:
  # -- Create PodMonitor resource for scraping metrics using PrometheusOperator
  enabled: false
  # -- Interval at which metrics should be scraped
  interval: "30s"
  # -- Add labels to the PodMonitor
  labels:
    release: prometheus

# -- Configure to PrometheusRule
prometheusRule:
  # -- If enabled, create PrometheusRule resource
  enabled: false
  # -- Additional annotations for the rules PrometheusRule resource
  annotations: {}
  # -- Additional labels for the rules PrometheusRule resource
  labels: {}
  # -- The namespace of prometheus rules
  namespace: ""
  # -- The prometheus rules
  rules: []
  # # These are examples rules, please adapt them to your needs
#    - alert: HighGRPCRequestLatency
#      expr: histogram_quantile(0.99, sum by(pod, le) (rate(greptime_servers_grpc_requests_elapsed_bucket[1m]))) > 1
#      for: 5s
#      labels:
#        severity: warning
#      annotations:
#        description: "The 99th percentile of gRPC request latency is above the threshold for pod: {{ $labels.pod }}"
#        summary: "High gRPC request latency for greptimedb pods"
#    - alert: HighHTTPRequestLatency
#      expr: histogram_quantile(0.99, sum by(pod, le) (rate(greptime_servers_http_requests_elapsed_bucket[1m]))) > 1
#      for: 5s
#      labels:
#        severity: warning
#      annotations:
#        description: "The 99th percentile of HTTP request latency is above the threshold for pod: {{ $labels.pod }}"
#        summary: "High HTTP request latency for greptimedb pods"
#    - alert: HighMySQLRequestLatency
#      expr: histogram_quantile(0.99, sum by(pod, le) (rate(greptime_servers_mysql_query_elapsed_bucket[1m]))) > 1
#      for: 5s
#      labels:
#        severity: warning
#      annotations:
#        description: "The 99th percentile of MySQL request latency is above the threshold for pod: {{ $labels.pod }}"
#        summary: "High MySQL request latency for greptimedb pods"
#    - alert: HighPostgreSQLRequestLatency
#      expr: histogram_quantile(0.99, sum by(pod, le) (rate(greptime_servers_postgres_query_elapsed_bucket[1m]))) > 1
#      for: 5s
#      labels:
#        severity: warning
#      annotations:
#        description: "The 99th percentile of PostgreSQL request latency is above the threshold for pod: {{ $labels.pod }}"
#        summary: "High PostgreSQL request latency for greptimedb pods"
#    - alert: CompactionFailures
#      expr: increase(greptime_mito_compaction_failure_total[1h]) > 2
#      for: 10m
#      labels:
#        severity: warning
#      annotations:
#        summary: "GreptimeDB compaction failures"
#        description: "GreptimeDB compaction failures have increased by more than {{ $value }} in the last hour"

# -- datanode instance groups configure, 'spec.datanode' and 'spec.datanodeGroups' cannot be set at the same time.
datanodeGroups: []
#  # -- Custom datanode name
#  - name: read
#    replicas: 1
#
#    # -- Extra raw toml config data of datanode.
#    config: |
#      [[region_engine]]
#      [region_engine.mito]
#      # Number of region workers
#      num_workers = 3
#
#    # -- The pod template for datanode
#    template:
#      main:
#        resources:
#          requests:
#            cpu: 2000m
#            memory: 2048Mi
#          limits:
#            cpu: 2000m
#            memory: 2048Mi
#
#  # -- Custom datanode name
#  - name: write
#    replicas: 1
#
#    # -- Extra raw toml config data of datanode.
#    config: |
#      [[region_engine]]
#      [region_engine.mito]
#      # Number of region workers
#      num_workers = 4
#
#    # -- The pod template for datanode
#    template:
#      main:
#        resources:
#          requests:
#            cpu: 2000m
#            memory: 2048Mi
#          limits:
#            cpu: 2000m
#            memory: 2048Mi

# -- Configure to object storage
objectStorage:
#  credentials:
#    secretName: ""

#    # AWS or AliCloud cloudProvider accessKeyID
#    accessKeyId: "you-should-set-the-access-key-id-here"

#    # AWS cloudProvider secretAccessKey
#    secretAccessKey: "you-should-set-the-secret-access-key-here"

#    # AliCloud cloudProvider accessKeySecret
#    accessKeySecret: "you-should-set-the-access-key-secret-here"

#    # Azure cloudProvider accountName and accountKey
#    accountName: "you-should-set-the-account-name-here"
#    accountKey: "you-should-set-the-account-key-here"

#    # GCP cloudProvider serviceAccountKey JSON-formatted base64 value
#    serviceAccountKey: "you-should-set-the-base64-service-account-key-here"

#    # Set the existing secret to get the key's of cloudProvider
#    existingSecretName: ""

  # Configure to use s3 storage.
  s3: {}
#    bucket: "bucket-name"
#    region: "us-west-2"

#    # The data directory in S3 will be: 's3://<bucket>/<root>/data/...'.
#    root: "mycluster"
#    endpoint: "s3.us-west-2.amazonaws.com"   # See more detail: https://docs.aws.amazon.com/general/latest/gr/s3.html

#    # Enable virtual host style so that OpenDAL will send API requests in virtual host style instead of path style.
#    # By default, OpenDAL will send API to 'https://s3.${region}.amazonaws.com/${BUCKET_NAME}'.
#    # If enableVirtualHostStyle is true, OpenDAL will send API to 'https://${BUCKET_NAME}.s3.${region}.amazonaws.com'.
#    enableVirtualHostStyle: false

  # Configure to use oss storage.
  oss: {}
#    bucket: "bucket-name"
#    region: "cn-hangzhou"

#    # The data directory in OSS will be: 'oss://<bucket>/<root>/data/...'.
#    root: "mycluster"
#    endpoint: "oss-cn-hangzhou.aliyuncs.com"

  # Configure to use gcs storage
  gcs: {}
  #  bucket: "bucket-name"
  #  scope: "" # example: "https://www.googleapis.com/auth/devstorage.read_write"

  #  # The data directory in gcs will be: 'gcs://<bucket>/<root>/data/...'.
  #  root: "mycluster"
  #  endpoint: "https://storage.googleapis.com"

  # Configure to use azblob storage
  azblob: {}
  #  container: ""
  #  endpoint: ""
  #  root: "mycluster"

  # Configure to object storage cache.
  cache: {}
  #  cacheCapacity: "20GiB"
  #  fs:
  #    # -- The storage class name
  #    storageClassName: null
  #    # -- The name of the wal
  #    name: cache
  #    # -- The storage size
  #    storageSize: 20Gi
  #    # -- The mount path
  #    mountPath: /cache

# -- Configure to remote wal
remoteWal:
  # -- Enable remote wal
  enabled: false
  # -- The remote wal type, only support kafka now.
  kafka:
    # -- The kafka broker endpoints
    brokerEndpoints: []

# -- Configure to dedicated wal
dedicatedWAL:
  # -- Enable dedicated wal
  enabled: false
  # -- Configure to raft engine
  raftEngine:
    # -- Configure to fs
    fs:
      # -- The storage class name
      storageClassName: null
      # -- The name of the wal
      name: wal
      # -- The storage size
      storageSize: 20Gi
      # -- The mount path
      mountPath: /wal

# -- Configure to frontend ingress
ingress: {}
 # -- Ingress annotations to apply to the ingress resource
 # annotations: {}
 #   example: frontend-ingress

 # -- Labels to apply to the ingress resource
 # labels: {}
 #   example: frontend-ingress

 # -- Specify the IngressClassName to use for the ingress
 # ingressClassName: nginx

 # -- The rules for routing traffic to the frontend service
 # rules:
 #   - host: ingress.example.com
 #     backends:
 #       - path: /
 #         pathType: Prefix  # Support to 'Prefix', 'ImplementationSpecific', 'Exact'.

 #       - name: read        # Specify the read frontend name if it exists.
 #         path: /
 #         pathType: Prefix
 #       - name: write       # Specify the write frontend name if it exists.
 #         path: /v1/sql
 #         pathType: Prefix

 # -- TLS configuration for securing the ingress traffic
 # tls:
 #   - secretName: frontend-ingress-tls
 #     hosts:
 #       - ingress.example.com

# -- The static auth for greptimedb, only support one user now(https://docs.greptime.com/user-guide/deployments-administration/authentication/static).
auth:
  # -- Enable static auth
  enabled: false
  # -- The auth file path to store the auth info
  mountPath: "/etc/greptimedb/auth"
  # -- The auth file name, the full path is `${mountPath}/${fileName}`
  fileName: "passwd"
  # -- The users to be created in the auth file
  users:
    - username: "admin"
      password: "admin"

# -- Configure to the debug pod
debugPod:
  # -- Enable debug pod, for more information see: "../../docker/debug-pod/README.md".
  enabled: false

  # -- The debug pod image
  image:
    registry: docker.io
    repository: greptime/greptime-tool
    tag: "20250606-04e3c7d"

  # -- The debug pod resource
  resources:
    requests:
      memory: 64Mi
      cpu: 50m
    limits:
      memory: 256Mi
      cpu: 200m

# -- Configure to the pre-check runner
preCheck:
  # -- Enable the pre-check runner
  enabled: false

  # -- The pre-check runner image
  image:
    registry: docker.io
    repository: greptime/greptime-tool
    tag: "20250421-94c4b8d"

  case:
    disk:
      enabled: false
      storageClass: null
      size: 20Gi
    s3:
      enabled: false
      bucket: "bucket-name"
      region: "s3-region"
      accessKeyID: "your-access-key-id"
      secretAccessKey: "your-secret-access-key"
    kafka:
      enabled: false
      endpoint: "your-kafka-endpoint"

  # -- Environment variables
  env: {}

# -- The monitoring bootstrap configuration
monitoring:
  # -- Enable monitoring
  enabled: false

  # -- Configure the standalone instance for storing monitoring data
  standalone: {}
#    base:
#      main:
#        # -- The standalone image, if not set, it will use the cluster image.
#        image: ""

#        resources:
#          # -- The requested resources for monitoring
#          requests: {}
# #            cpu: 500m
# #            memory: 512Mi

#          # -- The resources limits for monitoring
#          limits: {}
# #            cpu: "1"
# #            memory: "1Gi"

#        # -- The environment variables for the container
#        env: []

#        # -- The command to be executed in the container
#        command: []

#        # -- The arguments to be passed to the command
#        args: []

#      # -- The annotations to be created to the pod for monitoring
#      annotations: {}

#      # -- The standalone instance image pull secrets
#      imagePullSecrets: []
#        - name: "image-pull-secret"

#      # -- The labels to be created to the pod for monitoring
#      labels: {}

#      # -- The pod node selector for monitoring
#      nodeSelector: {}

#      # -- The pod tolerations for monitoring
#      tolerations: []

#      # -- The pod affinity for monitoring
#      affinity: {}

#      # -- The global service account for monitoring
#      serviceAccountName: ""
#     datanodeStorage:
#       fs:
#         # -- Storage class for datanode persistent volume
#         storageClassName: null
#         # -- Storage size for datanode persistent volume
#         storageSize: 50Gi
#         # -- Storage retain policy for datanode persistent volume
#         storageRetainPolicy: Retain
#         # -- The dataHome directory, default is "/data/greptimedb/"
#         dataHome: "/data/greptimedb"
#         # -- The data directory of the storage, default is "/data/greptimedb"
#         mountPath: "/data/greptimedb"
#         # -- The labels for the PVC that will be created
#         labels: {}
#         # -- The annotations for the PVC that will be created
#         annotations: {}

  # -- Configure the logs collection
  logsCollection:
    # -- The greptimedb pipeline for logs collection
    pipeline:
      data: ""

  # -- Configure vector for logs and metrics collection.
  vector:
    # -- vector image registry
    registry: docker.io
    # -- vector image repository
    repository: timberio/vector
    # -- vector image tag
    tag: 0.46.1-debian

    # -- vector resource
    resources:
      requests:
        cpu: "500m"
        memory: "256Mi"
      limits:
        cpu: "500m"
        memory: "256Mi"

# -- Global logging configuration
logging:
  # -- The log level for greptimedb, only support "debug", "info", "warn", "debug"
  level: "info"

  # -- The log format for greptimedb, only support "json" and "text"
  format: "text"

  # -- The logs directory for greptimedb
  logsDir: "/data/greptimedb/logs"

  # -- Whether to log to stdout only
  onlyLogToStdout: false

  # -- indicates whether to persist the log with the datanode data storage. It **ONLY** works for the datanode component.
  persistentWithData: false

  # -- The log filters, use the syntax of `target[span\{field=value\}]=level` to filter the logs.
  filters: []

# -- Global tracing configuration
tracing:
  # -- Enable tracing.
  enabled: false

  # -- The OTLP tracing endpoint.
  endpoint: "http://mycluster-monitor-standalone.default:4000/v1/otlp/v1/traces"

  # -- SampleRatio is the percentage of tracing will be sampled and exported.
  # Valid range `[0, 1]`, 1 means all traces are sampled, 0 means all traces are not sampled, the default value is 1.
  sampleRatio: "1.0"

# -- The slow query log configuration.
slowQuery:
  # -- Enable slow query log.
  enabled: true

  # -- The record type of slow query log.
  recordType: "system_table"

  # -- The threshold of slow query log in seconds.
  threshold: "30s"

  # -- Sample ratio of slow query log.
  sampleRatio: "1.0"

  # -- The TTL of slow query system table.
  ttl: "30d"

## -- The license configuration for enterprise features.
license:
  # -- Enable enterprise features.
  enabled: false
  # -- The secret name to store the license. If not set, it will use the ${release-name}-license.
  secretName: ""
  # -- The existing secret name to get the license.
  existingSecretName: ""
  # -- The license file path to store the license info.
  mountPath: "/etc/greptimedb/license"
  # -- The license file name.
  mountFileName: "current"
  # -- The license data. You can use `--set-file license.data=./license.txt` to set the license data.
  data: ""

# -- Deploy grafana dashboards for the grafana dashboard sidecar. https://github.com/grafana/helm-charts/tree/main/charts/grafana#sidecar-for-dashboards
dashboards:
  # -- Enable the grafana dashboards sidecar.
  enabled: false
  # -- The namespace in which the grafana dashboard configmaps are installed
  namespace: ""
  # -- The label as defined in the grafana helmchart. https://github.com/grafana/helm-charts/tree/main/charts/grafana#sidecar-for-dashboards
  label: grafana_dashboard
  # -- The label value as defined in the grafana helmchart. https://github.com/grafana/helm-charts/tree/main/charts/grafana#sidecar-for-dashboards
  labelValue: "1"
  # -- Additional annotation for the configmap
  annotations: {}
  # -- Extra labels for the configmap
  extraLabels: {}

####################################################
# Configuration for `grafana` child chart
####################################################
grafana:
  # -- Enable grafana deployment. It needs to enable monitoring `monitoring.enabled: true` first.
  enabled: false

  # -- The default admin username for grafana.
  adminUser: admin

  # -- The default admin password for grafana.
  adminPassword: gt-operator

  # -- The grafana image.
  image:
    # -- The grafana image registry.
    registry: docker.io
    # -- The grafana image repository.
    repository: grafana/grafana
    # -- The grafana image tag.
    tag: 11.6.0

  # -- The grafana sidecar settings to import dashboards
  sidecar:
    dashboards:
      enabled: true
      searchNamespace: ALL
      provider:
        allowUiUpdates: true

  # -- The grafana datasources.
  datasources:
    datasources.yaml:
      datasources:
        # Query the cluster metrics.
        - name: metrics
          type: prometheus
          url: http://mycluster-monitor-standalone.default.svc.cluster.local:4000/v1/prometheus
          access: proxy
          isDefault: true

        # Query the cluster traces.
        - name: traces
          type: jaeger
          url: http://mycluster-monitor-standalone.default.svc.cluster.local:4000/v1/jaeger
          access: proxy
          isDefault: true

        # Query the cluster logs and slow queries.
        - name: logs
          type: mysql
          url: mycluster-monitor-standalone.default.svc.cluster.local:4002
          access: proxy
          database: public

        # Query the information schema from the cluster.
        - name: information_schema
          type: mysql
          url: mycluster-frontend.default.svc.cluster.local:4002
          access: proxy
          database: information_schema

  # -- Init chown data for grafana.
  initChownData:
    # -- Enable init chown data for grafana.
    enabled: false

  # -- The grafana persistence configuration.
  persistence:
    # -- Whether to enable the persistence for grafana.
    enabled: true
    # -- The access modes for the grafana persistence.
    accessModes:
      - ReadWriteOnce
    # -- The storage size for the grafana persistence.
    size: 10Gi
    # -- The storageClassName for the grafana persistence.
    storageClassName: null

  # -- The grafana service configuration.
  service:
    # -- Whether to create the service for grafana.
    enabled: true
    # -- The grafana service port.
    port: 80
    # -- The type of the service.
    type: ClusterIP
    # -- The annotations for the grafana service.
    annotations: {}

####################################################
# Configuration for `jaeger-all-in-one` child chart
####################################################
jaeger-all-in-one:
  # -- Enable jaeger-all-in-one deployment.
  enabled: false

  # -- The jaeger-all-in-one image configuration.
  image:
    # -- The jaeger-all-in-one image repository.
    repository: jaegertracing/all-in-one
    # -- The jaeger-all-in-one image pull policy.
    pullPolicy: IfNotPresent
    # -- The jaeger-all-in-one image tag.
    versionOverride: latest

  # -- The jaeger-all-in-one service configuration.
  service:
    # -- The type of the service.
    type: ClusterIP
    # -- The service port.
    port: 16686
    # -- The annotations for the service.
    annotations: {}

  # -- The jaeger-all-in-one persistence configuration.
  volume:
    # -- Whether to enable the persistence for jaeger-all-in-one.
    enabled: true
    # -- The storageclass for the jaeger-all-in-one.
    className: ""
    # -- The storage size for the jaeger-all-in-one.
    size: 3Gi

  # -- Enable the zipkin collector for jaeger-all-in-one and listen on port 9411.
  enableHttpZipkinCollector: true

  # -- Enable the opentelemetry collector for jaeger-all-in-one and listen on port 4317.
  enableHttpOpenTelemetryCollector: true

  # -- The resources configurations for the jaeger-all-in-one.
  resources: {}
#    limits:
#     cpu: 100m
#     memory: 128Mi
#    requests:
#     cpu: 100m
#     memory: 128Mi

##############################################################
# Configuration for `greptimedb-remote-compaction` child chart
##############################################################
greptimedb-remote-compaction:
  # -- Enable remote compaction.
  enabled: false

  scheduler:
    # -- The scheduler image.
    image:
      # -- The scheduler image registry.
      registry: "Please set the registry"
      # -- The scheduler image repository.
      repository: "Please set the repository"
      # -- The scheduler image tag.
      tag: "Please set the tag"
      # -- The scheduler image pull policy.
      pullPolicy: IfNotPresent
      # -- The scheduler image pull secret.
      pullSecret: []

    # -- The scheduler replicas.
    replicas: 1

    # -- The scheduler command. It's used to override the default command.
    command: []

    # -- The scheduler args. It's used to override the default args.
    args: []

    # -- The scheduler resources.
    resources:
      requests:
        cpu: "500m"
        memory: "256Mi"
      limits:
        cpu: "4"
        memory: "8Gi"

    # -- The scheduler node selector.
    nodeSelector: {}

    # -- The scheduler affinity.
    affinity: {}

    # -- The scheduler tolerations.
    tolerations: []

    # -- The scheduler pod annotations.
    podAnnotations: {}

    # -- The scheduler pod labels.
    podLabels: {}

    # -- The scheduler service port.
    servicePort: 10099

    # -- The scheduler log level.
    logLevel: "info"

    # -- The scheduler service account.
    serviceAccount:
      # -- Create a service account for scheduler
      create: true
      # -- The annotations for scheduler service account
      annotations: {}

    # -- The scheduler extra config data.
    extraConfigData: |
      executorManager:
        removeInactiveExecutorsInterval: "2s"
        expiration: "5s"

  # -- The compactor configuration.
  compactor:
    # -- The compactor image.
    image:
      # -- The compactor image registry.
      registry: "Please set the registry"
      # -- The compactor image repository.
      repository: "Please set the repository"
      # -- The compactor image tag.
      tag: "Please set the tag"
      # -- The compactor image pull policy.
      pullPolicy: IfNotPresent
      # -- The compactor image pull secret.
      pullSecret: []

    # -- The compactor replicas.
    replicas: 1

    # -- The compactor command. It's used to override the default command.
    command: []

    # -- The compactor args. It's used to override the default args.
    args: []

    # -- The compactor resources.
    resources:
      requests:
        cpu: "500m"
        memory: "256Mi"
      limits:
        cpu: "4"
        memory: "8Gi"

    # -- The compactor node selector.
    nodeSelector: {}

    # -- The compactor affinity.
    affinity: {}

    # -- The compactor tolerations.
    tolerations: []

    # -- The compactor pod annotations.
    podAnnotations: {}

    # -- The compactor pod labels.
    podLabels: {}

    # -- The compactor service account.
    serviceAccount:
      # -- Create a service account for compactor
      create: true
      # -- The annotations for compactor service account
      annotations: {}

    # -- The compactor max background jobs.
    maxBackgroundJobs: 4

    # -- The compactor heartbeat interval.
    heartbeatInterval: "5s"

    # -- Configure to object storage
    objectStorage:
      # credentials:
      #   # AWS or AliCloud cloudProvider accessKeyID
      #   accessKeyId: ""

      #   # AWS cloudProvider secretAccessKey
      #   secretAccessKey: ""

      #   # AliCloud cloudProvider accessKeySecret
      #   accessKeySecret: ""

      #   Azure cloudProvider accountName and accountKey
      #   accountName: ""
      #   accountKey: ""

      #   GCP cloudProvider serviceAccountKey JSON-formatted base64 value
      #   serviceAccountKey: ""

      #   # Set the existing secret to get the key's of cloudProvider
      #   existingSecretName: ""

      # configure to use s3 storage
      s3: {}
        # bucket: ""
        # region: ""
        # root: ""
        # endpoint: ""

      # configure to use oss storage
      oss: {}
      #  bucket: ""
      #  region: ""

      #  # The data directory in OSS will be: 'oss://<bucket>/<root>/data/...'.
      #  root: ""
      #  endpoint: ""

      # configure to use gcs storage
      gcs: {}
      #  bucket: ""
      #  scope: "" # example: "https://www.googleapis.com/auth/devstorage.read_write"

      #  # The data directory in gcs will be: 'gcs://<bucket>/<root>/data/...'.
      #  root: ""
      #  endpoint: "https://storage.googleapis.com"

      # configure to use azblob storage
      azblob: {}
      #  container: ""
      #  endpoint: ""
      #  root: ""

    logging:
      # The level of the log. Only support "debug", "info", "warn", "error".
      level: "info"
      # The format of the log. Only support "text", "json".
      format: "text"

    # -- The compactor config data.
    extraConfigData: ""

#################################################################
# Configuration for `greptimedb-enterprise-dashboard` child chart
#################################################################
greptimedb-enterprise-dashboard:
  # -- Enable greptimedb-enterprise-dashboard deployment.
  enabled: false

  replicaCount: 1

  image:
    repository: "Please set the image repository"
    pullPolicy: IfNotPresent
    tag: "Please set the image repository"

  imagePullSecrets: []
  nameOverride: ""
  fullnameOverride: ""

  args:
    - --config=/etc/dashboard-apiserver/config.yaml

  config: |
    servicePort: 19095
    logLevel: info
    provisionedInstances:
    - name: mycluster
      namespace: default
      type: cluster
      url: http://mycluster-frontend.default.svc.cluster.local:4000
      monitoring:
        greptimedb:
          url: http://mycluster-monitor-standalone.default.svc.cluster.local:4000

  servicePort: 19095

  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""

  podAnnotations: {}

  podSecurityContext: {}
    # fsGroup: 2000

  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000

  service:
    type: ClusterIP
    port: 19095
    annotations: {}

  resources: {}
  #  requests:
  #    cpu: 100m
  #    memory: 128Mi
  #  limits:
  #    cpu: 100m
  #    memory: 128Mi

  nodeSelector: {}

  tolerations: []

  affinity: {}
